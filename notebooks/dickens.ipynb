{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nrhodes/.local/lib/python3.6/site-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n",
      "/home/nrhodes/.local/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import fastai\n",
    "\n",
    "from fastai.io import *\n",
    "\n",
    "from fastai.column_data import *\n",
    "from fastai.text import *\n",
    "\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning to generate Dickens-like text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "davidcopperfield.txt  \u001b[0m\u001b[01;34mmodels\u001b[0m/  \u001b[01;34mtmp\u001b[0m/  \u001b[01;34mtrn\u001b[0m/  \u001b[01;34mval\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "from torchtext import vocab, data\n",
    "\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "PATH=Path('../data/dickens/')\n",
    "\n",
    "TRN_PATH = 'trn'\n",
    "VAL_PATH = 'val'\n",
    "TRN = PATH / TRN_PATH\n",
    "VAL = PATH / VAL_PATH\n",
    "\n",
    "%ls {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 53, 1, 1494913)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=list)\n",
    "bs=2048; bptt=16; n_fac=42; n_hidden=256\n",
    "\n",
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
    "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=3)\n",
    "\n",
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSequence(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs, nl):\n",
    "        super().__init__()\n",
    "        self.vocab_size,self.nl = vocab_size,nl\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.dropout = nn.Dropout(.1)\n",
    "        self.rnn = nn.GRU(n_fac, n_hidden, nl, dropout=0.0)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h[0].size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.dropout(self.e(cs)), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        self.h = V(torch.zeros(self.nl, bs, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38f2c0197c347d1b30d3b3364310396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=127), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   \n",
      "    0      2.422565   2.140659  \n",
      "    1      2.0522     1.785665  \n",
      "    2      1.86702    1.733811  \n",
      "    3      1.777272   1.680565  \n",
      "    4      1.706417   1.62905   \n",
      "    5      1.652503   1.621268  \n",
      "    6      1.615807   1.609822  \n",
      "    7      1.62899    1.64069   \n",
      "    8      1.624412   1.640711  \n",
      "    9      1.609931   1.576252  \n",
      "    10     1.58831    1.577713  \n",
      "    11     1.566153   1.559515  \n",
      "    12     1.536029   1.556644  \n",
      "    13     1.516173   1.535826  \n",
      "    14     1.499759   1.513017  \n",
      "    15     1.588607   1.658486  \n",
      "    16     1.594105   1.588101  \n",
      "    17     1.600745   1.583522  \n",
      "    18     1.585102   1.598893  \n",
      "    19     1.58912    1.595601  \n",
      "    20     1.568464   1.552763  \n",
      "    21     1.565605   1.565839  \n",
      "    22     1.541029   1.5718    \n",
      "    23     1.515897   1.523929  \n",
      "    24     1.515345   1.523382  \n",
      "    25     1.505235   1.520322  \n",
      "    26     1.484016   1.52308   \n",
      "    27     1.481771   1.507402  \n",
      "    28     1.471043   1.505026  \n",
      "    29     1.487299   1.481391  \n",
      "    30     1.482542   1.497197  \n",
      "    31     1.519054   1.571984  \n",
      "    32     1.56271    1.578905  \n",
      "    33     1.589013   1.6059    \n",
      "    34     1.563436   1.583698  \n",
      "    35     1.566004   1.594969  \n",
      "    36     1.569464   1.576831  \n",
      "    37     1.553152   1.55527   \n",
      "    38     1.53321    1.536658  \n",
      "    39     1.535649   1.527699  \n",
      "    40     1.526954   1.556361  \n",
      "    41     1.542981   1.562968  \n",
      "    42     1.523219   1.528568  \n",
      "    43     1.513907   1.546425  \n",
      "    44     1.502146   1.507347  \n",
      "    45     1.517274   1.53847   \n",
      "    46     1.513001   1.524247  \n",
      "    47     1.520893   1.524104  \n",
      "    48     1.518812   1.498469  \n",
      "    49     1.505094   1.51801   \n",
      "    50     1.495162   1.548759  \n",
      "    51     1.475246   1.498707  \n",
      "    52     1.484988   1.494112  \n",
      "    53     1.484505   1.482746  \n",
      "    54     1.476023   1.486158  \n",
      "    55     1.458423   1.493671  \n",
      "    56     1.455783   1.475829  \n",
      "    57     1.461206   1.51858   \n",
      "    58     1.453909   1.485143  \n",
      "    59     1.461602   1.51815   \n",
      "    60     1.465722   1.501816  \n",
      "    61     1.45202    1.486845  \n",
      "    62     1.446311   1.494105  \n",
      "    63     1.483625   1.573757  \n",
      "    64     1.518184   1.564512  \n",
      "    65     1.564232   1.584611  \n",
      "    66     1.554026   1.558859  \n",
      "    67     1.553105   1.573037  \n",
      "    68     1.534485   1.553446  \n",
      "    69     1.533792   1.54858   \n",
      "    70     1.532713   1.577247  \n",
      "    71     1.527069   1.513835  \n",
      "    72     1.517854   1.537054  \n",
      "    73     1.539729   1.565746  \n",
      "    74     1.516061   1.541423  \n",
      "    75     1.53596    1.573992  \n",
      "    76     1.525425   1.563451  \n",
      "    77     1.526872   1.546155  \n",
      "    78     1.534649   1.551052  \n",
      "    79     1.546218   1.585171  \n",
      "    80     1.527617   1.532953  \n",
      "    81     1.518643   1.536633  \n",
      "    82     1.52908    1.543983  \n",
      "    83     1.506133   1.514201  \n",
      "    84     1.513872   1.51326   \n",
      "    85     1.521928   1.557395  \n",
      "    86     1.51559    1.535478  \n",
      "    87     1.511867   1.524818  \n",
      "    88     1.507733   1.508853  \n",
      "    89     1.511763   1.543966  \n",
      "    90     1.506769   1.533463  \n",
      "    91     1.506401   1.537956  \n",
      "    92     1.503695   1.532193  \n",
      "    93     1.491327   1.517953  \n",
      "    94     1.483688   1.500575  \n",
      "    95     1.485314   1.509935  \n",
      "    96     1.485409   1.521011  \n",
      "    97     1.493101   1.519739  \n",
      "    98     1.495063   1.508884  \n",
      "    99     1.487837   1.504981  \n",
      "   100     1.483096   1.502188  \n",
      "   101     1.475926   1.493031  \n",
      "   102     1.467099   1.544024  \n",
      "   103     1.463017   1.475142  \n",
      "   104     1.44997    1.468242  \n",
      "   105     1.449693   1.499813  \n",
      "   106     1.459062   1.523801  \n",
      "   107     1.458244   1.480745  \n",
      "   108     1.445913   1.487872  \n",
      "   109     1.434961   1.52357   \n",
      "   110     1.449237   1.480564  \n",
      "   111     1.442039   1.479275  \n",
      "   112     1.439357   1.47735   \n",
      "   113     1.439672   1.484291  \n",
      "   114     1.450996   1.4765    \n",
      "   115     1.443026   1.495891  \n",
      "   116     1.450978   1.457836  \n",
      "   117     1.471384   1.469665  \n",
      "   118     1.456933   1.496735  \n",
      "   119     1.451237   1.452939  \n",
      "   120     1.430934   1.497082  \n",
      "   121     1.422585   1.481834  \n",
      "   122     1.423931   1.482123  \n",
      "   123     1.421612   1.483109  \n",
      "   124     1.418528   1.476035  \n",
      "   125     1.409233   1.478397  \n",
      "   126     1.429226   1.471596  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.4716])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char = CharSequence(md.nt, n_fac, n_hidden, 1)\n",
    "if torch.cuda.is_available():\n",
    "    char = char.cuda()\n",
    "m = BasicModel(char)\n",
    "learner = RNN_Learner(md, m, opt_fn=optim.Adam, crit=F.nll_loss)\n",
    "\n",
    "#minimum_learning_rate_divisor = 1200\n",
    "#percent_after_triangle_cycle = 15\n",
    "#max_momentum=.97\n",
    "#min_momentum=.85\n",
    "#learner.fit(1e-2, 1, cycle_len=72, \n",
    "#           use_clr_beta=(minimum_learning_rate_divisor, \n",
    "#                         percent_after_triangle_cycle, \n",
    "#                         max_momentum, \n",
    "#                         min_momentum),\n",
    "#                         wds=1e-5)\n",
    "learner.fit(2e-2, 7, cycle_mult=2, cycle_len=1, \n",
    "           wds=1e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    device = None if torch.cuda.is_available() else -1\n",
    "    idxs = TEXT.numericalize(inp, device=device, train=False)\n",
    "    p = learner.model(VV(idxs.transpose(0,1)))\n",
    "    r = torch.multinomial(p[-1].exp(), 1)\n",
    "    return TEXT.vocab.itos[to_np(r)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')\n",
    "#TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fourscore and seven years agony of the rooks with me in the adverting. i was certain by further thanour houked.‘mutt--that i wasgo by the sy-point. they seethink of my son;but topity that she desired in a handkarch. ‘--change enough to murdstone. i really remember thatshe had one of me, and that tened them atmany napid scarrierydo?” yet find a frivly; and then the solicitof ‘having, and if mr. quinion traddles, ‘ifeversible h\n"
     ]
    }
   ],
   "source": [
    "print(get_next_n('fourscore and seven years ago', 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs152]",
   "language": "python",
   "name": "conda-env-cs152-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "216px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
